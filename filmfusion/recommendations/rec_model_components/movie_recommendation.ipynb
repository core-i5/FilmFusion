{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9125a31-9e35-407d-a4e6-3ea83727584f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     id                        title  \\\n",
      "0           0    238                The Godfather   \n",
      "1           1    278     The Shawshank Redemption   \n",
      "2           2    240        The Godfather Part II   \n",
      "3           3  19404  Dilwale Dulhania Le Jayenge   \n",
      "4           4    424             Schindler's List   \n",
      "\n",
      "                                            overview release_date  popularity  \\\n",
      "0  Spanning the years 1945 to 1955, a chronicle o...   1972-03-14     127.351   \n",
      "1  Framed in the 1940s for the double murder of h...   1994-09-23      91.282   \n",
      "2  In the continuing saga of the Corleone crime f...   1974-12-20      67.617   \n",
      "3  Raj is a rich, carefree, happy-go-lucky second...   1995-10-20      34.208   \n",
      "4  The true story of how businessman Oskar Schind...   1993-12-15      56.547   \n",
      "\n",
      "   vote_average  vote_count  \n",
      "0           8.7       18285  \n",
      "1           8.7       24196  \n",
      "2           8.6       11033  \n",
      "3           8.6        4183  \n",
      "4           8.6       14301  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "# We'll start by loading and preprocessing the data.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "file_path = 'TMDB_Movies.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Convert release_date to datetime\n",
    "data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')\n",
    "\n",
    "# Handle missing values (e.g., drop rows with missing 'overview')\n",
    "data.dropna(subset=['overview'], inplace=True)\n",
    "\n",
    "# Normalize popularity and vote_average\n",
    "scaler = MinMaxScaler()\n",
    "data[['popularity', 'vote_average']] = scaler.fit_transform(data[['popularity', 'vote_average']])\n",
    "\n",
    "# Prepare content features using TF-IDF for 'overview'\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['overview'])\n",
    "\n",
    "# Add TF-IDF matrix to the data frame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=data.index)\n",
    "data = pd.concat([data, tfidf_df], axis=1)\n",
    "\n",
    "# Save the preprocessed data to a CSV file\n",
    "preprocessed_file_path = 'preprocessed_data.csv'\n",
    "data.to_csv(preprocessed_file_path)\n",
    "# data.to_csv(preprocessed_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5e04e2-5a74-47db-9353-2b25c21d1e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9998"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb138ead-76b0-4c1d-b98a-1f47e8cf0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Collaborative Filtering Implementation \\n\n",
    "# We will use matrix factorization with Singular Value Decomposition (SVD) for collaborative filtering.\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Assume we have a user-item interaction matrix 'user_item_matrix'\n",
    "# Example: user_item_matrix[user_id][movie_id] = rating\n",
    "# For the purpose of this example, we will simulate this matrix\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample user-item matrix\n",
    "n_users = 100\n",
    "n_movies = data.shape[0]\n",
    "np.random.seed(42)\n",
    "user_item_matrix = np.random.rand(n_users, n_movies)\n",
    "\n",
    "# Apply SVD\n",
    "U, sigma, Vt = svds(user_item_matrix, k=50)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruct the matrix\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "\n",
    "# Convert to DataFrame for ease of use\n",
    "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a373a92-7d2e-4098-a9d8-74e2e9cc0886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6815                                         The Blackout\n",
      "2567                                              Mummies\n",
      "39      The Lord of the Rings: The Fellowship of the Ring\n",
      "45                  The Lord of the Rings: The Two Towers\n",
      "7258                        Tom and Jerry: The Magic Ring\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Content-Based Filtering Implementation\n",
    "# We already prepared the TF-IDF matrix for content-based filtering. Now, we will use cosine similarity to find similar movies.\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get movie recommendations based on content similarity\n",
    "def get_content_recommendations(movie_id, num_recommendations=10):\n",
    "    movie_idx = data[data['id'] == movie_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:num_recommendations+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return data['title'].iloc[movie_indices]\n",
    "\n",
    "# Example usage\n",
    "print(get_content_recommendations(movie_id=123, num_recommendations=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f443a944-dc4e-48f7-83d2-9c936afe4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blood Red Sky', 'Fading Gigolo', 'Death Race 2', \"Don't Torture a Duckling\", 'The White Sheik']\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Hybrid Model Construction\n",
    "# We will combine the collaborative and content-based approaches by averaging their scores.\n",
    "\n",
    "def hybrid_recommendations(user_id, movie_id, num_recommendations=10):\n",
    "    # Get collaborative filtering recommendations\n",
    "    user_ratings = predicted_ratings_df.loc[user_id]\n",
    "    cf_recommendations = user_ratings.sort_values(ascending=False).index[:num_recommendations]\n",
    "    \n",
    "    # Get content-based recommendations\n",
    "    content_recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "    \n",
    "    # Combine recommendations\n",
    "    combined_recommendations = list(set(cf_recommendations).union(set(content_recommendations.index)))\n",
    "    combined_scores = {}\n",
    "    \n",
    "    for idx in combined_recommendations:\n",
    "        cf_score = user_ratings[idx]\n",
    "        content_score = cosine_sim[movie_id][idx]\n",
    "        combined_scores[idx] = (cf_score + content_score) / 2\n",
    "    \n",
    "    # Sort combined scores\n",
    "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "    return [data['title'].iloc[idx] for idx, score in sorted_recommendations]\n",
    "\n",
    "# Example usage\n",
    "print(hybrid_recommendations(user_id=10, movie_id=123, num_recommendations=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54d20222-d612-4d8a-a5f4-b345e976387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative Filtering RMSE: 0.1952269266979494\n",
      "Content-Based Filtering Precision: 0.1, Recall: 0.0005\n",
      "Hybrid Model Precision: 0.5, Recall: 0.0025\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Model Training and Evaluation\n",
    "# To evaluate the models, we'll use metrics like RMSE for collaborative filtering and precision/recall for content-based and hybrid models.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Create train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluate collaborative filtering\n",
    "def evaluate_cf(predicted_ratings, actual_ratings):\n",
    "    rmse = sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "    return rmse\n",
    "\n",
    "# Simulate actual ratings for evaluation\n",
    "actual_ratings = user_item_matrix  # In practice, this would be the actual ratings from a test set\n",
    "\n",
    "# Evaluate content-based filtering\n",
    "def evaluate_content_based(movie_id, actual_data, num_recommendations=10):\n",
    "    recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "    relevant_items = actual_data['title'].values\n",
    "    recommended_items = recommendations\n",
    "    \n",
    "    precision = len(set(recommended_items) & set(relevant_items)) / len(recommended_items)\n",
    "    recall = len(set(recommended_items) & set(relevant_items)) / len(relevant_items)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Evaluate hybrid model\n",
    "def evaluate_hybrid(user_id, movie_id, actual_data, num_recommendations=10):\n",
    "    recommendations = hybrid_recommendations(user_id, movie_id, num_recommendations)\n",
    "    relevant_items = actual_data['title'].values\n",
    "    recommended_items = recommendations\n",
    "    \n",
    "    precision = len(set(recommended_items) & set(relevant_items)) / len(recommended_items)\n",
    "    recall = len(set(recommended_items) & set(relevant_items)) / len(relevant_items)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Example evaluation\n",
    "cf_rmse = evaluate_cf(predicted_ratings, actual_ratings)\n",
    "print(f\"Collaborative Filtering RMSE: {cf_rmse}\")\n",
    "\n",
    "content_precision, content_recall = evaluate_content_based(movie_id=data['id'].iloc[0], actual_data=test_data, num_recommendations=10)\n",
    "print(f\"Content-Based Filtering Precision: {content_precision}, Recall: {content_recall}\")\n",
    "\n",
    "hybrid_precision, hybrid_recall = evaluate_hybrid(user_id=10, movie_id=data['id'].iloc[0], actual_data=test_data, num_recommendations=10)\n",
    "print(f\"Hybrid Model Precision: {hybrid_precision}, Recall: {hybrid_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5abfe5f0-8315-4b81-9c7e-1a6057d9ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save the Model Components\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Save the TF-IDF Vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# Save the SVD Components\n",
    "with open('U_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(U, f)\n",
    "\n",
    "with open('sigma_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(sigma, f)\n",
    "\n",
    "with open('Vt_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(Vt, f)\n",
    "\n",
    "# Save the Cosine Similarity Matrix\n",
    "np.save('cosine_sim.npy', cosine_sim)\n",
    "\n",
    "# Save the Predicted Ratings DataFrame\n",
    "predicted_ratings_df.to_pickle('predicted_ratings_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b40f8012-1bd0-436c-b62d-b561374fd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Load existing components and models\n",
    "\n",
    "data = pd.read_csv('preprocessed_data.csv')\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "with open('U_matrix.pkl', 'rb') as f:\n",
    "    U = pickle.load(f)\n",
    "with open('sigma_matrix.pkl', 'rb') as f:\n",
    "    sigma = pickle.load(f)\n",
    "with open('Vt_matrix.pkl', 'rb') as f:\n",
    "    Vt = pickle.load(f)\n",
    "\n",
    "cosine_sim = np.load('cosine_sim.npy')\n",
    "predicted_ratings_df = pd.read_pickle('predicted_ratings_df.pkl')\n",
    "\n",
    "def get_content_recommendations(movie_id, num_recommendations=10):\n",
    "    movie_idx = data[data['id'] == movie_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:num_recommendations+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in movie_indices]\n",
    "\n",
    "def get_popularity_recommendations(num_recommendations=10):\n",
    "    popular_movies = data.sort_values('popularity', ascending=False)\n",
    "    movie_indices = popular_movies.index[:num_recommendations]\n",
    "    return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in movie_indices]\n",
    "\n",
    "def hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=10):\n",
    "    if user_id is None or user_id not in predicted_ratings_df.index:\n",
    "        if movie_id is not None:\n",
    "            return get_content_recommendations(movie_id, num_recommendations)\n",
    "        else:\n",
    "            return get_popularity_recommendations(num_recommendations)\n",
    "    else:\n",
    "        user_ratings = predicted_ratings_df.loc[user_id]\n",
    "        cf_recommendations = user_ratings.sort_values(ascending=False).index[:num_recommendations]\n",
    "\n",
    "        if movie_id is not None:\n",
    "            content_recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "            combined_recommendations = list(set(cf_recommendations).union(set([idx for idx, title in content_recommendations])))\n",
    "            combined_scores = {}\n",
    "\n",
    "            movie_idx = data[data['id'] == movie_id].index[0]\n",
    "            for idx in combined_recommendations:\n",
    "                cf_score = user_ratings.get(idx, 0)\n",
    "                content_score = cosine_sim[movie_idx][idx] if idx < len(cosine_sim) else 0\n",
    "                combined_scores[idx] = (cf_score + content_score) / 2\n",
    "\n",
    "            sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "            return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx, score in sorted_recommendations]\n",
    "        else:\n",
    "            return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in cf_recommendations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e8a0e2-d766-4b6d-bebd-f4be95b6ca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for new user based on movie ID 299534:\n",
      "[(299536, 'Avengers: Infinity War'), (271110, 'Captain America: Civil War'), (14613, 'Next Avengers: Heroes of Tomorrow'), (340382, 'Attack on Titan II: End of the World'), (299537, 'Captain Marvel')]\n",
      "Recommendations for existing user with user ID 10:\n",
      "[(214030, 'Fading Gigolo'), (760883, 'Blood Red Sky'), (49361, \"Don't Torture a Duckling\"), (51620, 'Death Race 2'), (43361, 'The White Sheik')]\n",
      "Recommendations for existing user with user ID 10 and movie ID 299534:\n",
      "[(760883, 'Blood Red Sky'), (214030, 'Fading Gigolo'), (49361, \"Don't Torture a Duckling\"), (51620, 'Death Race 2'), (43361, 'The White Sheik')]\n",
      "Recommendations without user ID or movie ID:\n",
      "[(346698, 'Barbie'), (298618, 'The Flash'), (667538, 'Transformers: Rise of the Beasts'), (1040148, 'Ruby Gillman, Teenage Kraken'), (447365, 'Guardians of the Galaxy Vol. 3')]\n"
     ]
    }
   ],
   "source": [
    "# Example usage for different scenarios\n",
    "new_user_movie_id = 299534  # Movie ID for \"Avengers: Endgame\"\n",
    "recommendations = hybrid_recommendations(user_id=None, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "print(f\"Recommendations for new user based on movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "existing_user_id = 10  # Assuming user ID 10 exists in predicted_ratings_df\n",
    "recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=None, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id} and movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "recommendations = hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=5)\n",
    "print(f\"Recommendations without user ID or movie ID:\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513ef9c-f4ac-4be1-9fe6-1b4de74f3f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
