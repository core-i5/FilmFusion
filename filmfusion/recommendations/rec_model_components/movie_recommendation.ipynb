{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9125a31-9e35-407d-a4e6-3ea83727584f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     id                        title  \\\n",
      "0           0    238                The Godfather   \n",
      "1           1    278     The Shawshank Redemption   \n",
      "2           2    240        The Godfather Part II   \n",
      "3           3  19404  Dilwale Dulhania Le Jayenge   \n",
      "4           4    424             Schindler's List   \n",
      "\n",
      "                                            overview release_date  popularity  \\\n",
      "0  Spanning the years 1945 to 1955, a chronicle o...   1972-03-14     127.351   \n",
      "1  Framed in the 1940s for the double murder of h...   1994-09-23      91.282   \n",
      "2  In the continuing saga of the Corleone crime f...   1974-12-20      67.617   \n",
      "3  Raj is a rich, carefree, happy-go-lucky second...   1995-10-20      34.208   \n",
      "4  The true story of how businessman Oskar Schind...   1993-12-15      56.547   \n",
      "\n",
      "   vote_average  vote_count  \n",
      "0           8.7       18285  \n",
      "1           8.7       24196  \n",
      "2           8.6       11033  \n",
      "3           8.6        4183  \n",
      "4           8.6       14301  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "# We'll start by loading and preprocessing the data.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "file_path = 'TMDB_Movies.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Convert release_date to datetime\n",
    "data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')\n",
    "\n",
    "# Handle missing values (e.g., drop rows with missing 'overview')\n",
    "data.dropna(subset=['overview'], inplace=True)\n",
    "\n",
    "# Normalize popularity and vote_average\n",
    "scaler = MinMaxScaler()\n",
    "data[['popularity', 'vote_average']] = scaler.fit_transform(data[['popularity', 'vote_average']])\n",
    "\n",
    "# Prepare content features using TF-IDF for 'overview'\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['overview'])\n",
    "\n",
    "# Add TF-IDF matrix to the data frame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=data.index)\n",
    "data = pd.concat([data, tfidf_df], axis=1)\n",
    "\n",
    "# Save the preprocessed data to a CSV file\n",
    "preprocessed_file_path = 'new_preprocessed_data.csv'\n",
    "data.to_csv(preprocessed_file_path)\n",
    "# data.to_csv(preprocessed_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5e04e2-5a74-47db-9353-2b25c21d1e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9998"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb138ead-76b0-4c1d-b98a-1f47e8cf0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Collaborative Filtering Implementation \\n\n",
    "# We will use matrix factorization with Singular Value Decomposition (SVD) for collaborative filtering.\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Assume we have a user-item interaction matrix 'user_item_matrix'\n",
    "# Example: user_item_matrix[user_id][movie_id] = rating\n",
    "# For the purpose of this example, we will simulate this matrix\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample user-item matrix\n",
    "n_users = 100\n",
    "n_movies = data.shape[0]\n",
    "np.random.seed(42)\n",
    "user_item_matrix = np.random.rand(n_users, n_movies)\n",
    "\n",
    "# Apply SVD\n",
    "U, sigma, Vt = svds(user_item_matrix, k=50)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruct the matrix\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "\n",
    "# Convert to DataFrame for ease of use\n",
    "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a373a92-7d2e-4098-a9d8-74e2e9cc0886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6815                                         The Blackout\n",
      "2567                                              Mummies\n",
      "39      The Lord of the Rings: The Fellowship of the Ring\n",
      "45                  The Lord of the Rings: The Two Towers\n",
      "7258                        Tom and Jerry: The Magic Ring\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Content-Based Filtering Implementation\n",
    "# We already prepared the TF-IDF matrix for content-based filtering. Now, we will use cosine similarity to find similar movies.\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get movie recommendations based on content similarity\n",
    "def get_content_recommendations(movie_id, num_recommendations=10):\n",
    "    movie_idx = data[data['id'] == movie_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:num_recommendations+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return data['title'].iloc[movie_indices]\n",
    "\n",
    "# Example usage\n",
    "print(get_content_recommendations(movie_id=123, num_recommendations=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f443a944-dc4e-48f7-83d2-9c936afe4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blood Red Sky', 'Fading Gigolo', 'Death Race 2', \"Don't Torture a Duckling\", 'The White Sheik']\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Hybrid Model Construction\n",
    "# We will combine the collaborative and content-based approaches by averaging their scores.\n",
    "\n",
    "def hybrid_recommendations(user_id, movie_id, num_recommendations=10):\n",
    "    # Get collaborative filtering recommendations\n",
    "    user_ratings = predicted_ratings_df.loc[user_id]\n",
    "    cf_recommendations = user_ratings.sort_values(ascending=False).index[:num_recommendations]\n",
    "    \n",
    "    # Get content-based recommendations\n",
    "    content_recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "    \n",
    "    # Combine recommendations\n",
    "    combined_recommendations = list(set(cf_recommendations).union(set(content_recommendations.index)))\n",
    "    combined_scores = {}\n",
    "    \n",
    "    for idx in combined_recommendations:\n",
    "        cf_score = user_ratings[idx]\n",
    "        content_score = cosine_sim[movie_id][idx]\n",
    "        combined_scores[idx] = (cf_score + content_score) / 2\n",
    "    \n",
    "    # Sort combined scores\n",
    "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "    return [data['title'].iloc[idx] for idx, score in sorted_recommendations]\n",
    "\n",
    "# Example usage\n",
    "print(hybrid_recommendations(user_id=10, movie_id=123, num_recommendations=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54d20222-d612-4d8a-a5f4-b345e976387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative Filtering RMSE: 0.1952269266979494\n",
      "Content-Based Filtering Precision: 0.1, Recall: 0.0005\n",
      "Hybrid Model Precision: 0.5, Recall: 0.0025\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Model Training and Evaluation\n",
    "# To evaluate the models, we'll use metrics like RMSE for collaborative filtering and precision/recall for content-based and hybrid models.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Create train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluate collaborative filtering\n",
    "def evaluate_cf(predicted_ratings, actual_ratings):\n",
    "    rmse = sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "    return rmse\n",
    "\n",
    "# Simulate actual ratings for evaluation\n",
    "actual_ratings = user_item_matrix  # In practice, this would be the actual ratings from a test set\n",
    "\n",
    "# Evaluate content-based filtering\n",
    "def evaluate_content_based(movie_id, actual_data, num_recommendations=10):\n",
    "    recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "    relevant_items = actual_data['title'].values\n",
    "    recommended_items = recommendations\n",
    "    \n",
    "    precision = len(set(recommended_items) & set(relevant_items)) / len(recommended_items)\n",
    "    recall = len(set(recommended_items) & set(relevant_items)) / len(relevant_items)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Evaluate hybrid model\n",
    "def evaluate_hybrid(user_id, movie_id, actual_data, num_recommendations=10):\n",
    "    recommendations = hybrid_recommendations(user_id, movie_id, num_recommendations)\n",
    "    relevant_items = actual_data['title'].values\n",
    "    recommended_items = recommendations\n",
    "    \n",
    "    precision = len(set(recommended_items) & set(relevant_items)) / len(recommended_items)\n",
    "    recall = len(set(recommended_items) & set(relevant_items)) / len(relevant_items)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Example evaluation\n",
    "cf_rmse = evaluate_cf(predicted_ratings, actual_ratings)\n",
    "print(f\"Collaborative Filtering RMSE: {cf_rmse}\")\n",
    "\n",
    "content_precision, content_recall = evaluate_content_based(movie_id=data['id'].iloc[0], actual_data=test_data, num_recommendations=10)\n",
    "print(f\"Content-Based Filtering Precision: {content_precision}, Recall: {content_recall}\")\n",
    "\n",
    "hybrid_precision, hybrid_recall = evaluate_hybrid(user_id=10, movie_id=data['id'].iloc[0], actual_data=test_data, num_recommendations=10)\n",
    "print(f\"Hybrid Model Precision: {hybrid_precision}, Recall: {hybrid_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5abfe5f0-8315-4b81-9c7e-1a6057d9ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save the Model Components\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Save the TF-IDF Vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# Save the SVD Components\n",
    "with open('U_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(U, f)\n",
    "\n",
    "with open('sigma_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(sigma, f)\n",
    "\n",
    "with open('Vt_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(Vt, f)\n",
    "\n",
    "# Save the Cosine Similarity Matrix\n",
    "np.save('cosine_sim.npy', cosine_sim)\n",
    "\n",
    "# Save the Predicted Ratings DataFrame\n",
    "predicted_ratings_df.to_pickle('predicted_ratings_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff8ea6e7-b43f-4411-8f3f-21d0453a722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Load the Model Components\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the TF-IDF Vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Load the SVD Components\n",
    "with open('U_matrix.pkl', 'rb') as f:\n",
    "    U = pickle.load(f)\n",
    "\n",
    "with open('sigma_matrix.pkl', 'rb') as f:\n",
    "    sigma = pickle.load(f)\n",
    "\n",
    "with open('Vt_matrix.pkl', 'rb') as f:\n",
    "    Vt = pickle.load(f)\n",
    "\n",
    "# Load the Cosine Similarity Matrix\n",
    "cosine_sim = np.load('cosine_sim.npy')\n",
    "\n",
    "# Load the Predicted Ratings DataFrame\n",
    "predicted_ratings_df = pd.read_pickle('predicted_ratings_df.pkl')\n",
    "\n",
    "# Reconstruct the predicted ratings matrix\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d9b4655-73ad-42d3-9c53-94b05ab15646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for new user based on movie ID 299534:\n",
      "99                    Avengers: Infinity War\n",
      "1638              Captain America: Civil War\n",
      "4250       Next Avengers: Heroes of Tomorrow\n",
      "8455    Attack on Titan II: End of the World\n",
      "4360                          Captain Marvel\n",
      "Name: title, dtype: object\n",
      "Recommendations for existing user with user ID 10:\n",
      "['Blood Red Sky', 'Fading Gigolo', \"Don't Torture a Duckling\", 'Death Race 2', 'The White Sheik']\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "\n",
    "# # Load the data\n",
    "# file_path = '/mnt/data/TMDB_Movies.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# # Load the Cosine Similarity Matrix\n",
    "# cosine_sim = np.load('cosine_sim.npy')\n",
    "\n",
    "# # Load the Predicted Ratings DataFrame for existing users\n",
    "# predicted_ratings_df = pd.read_pickle('predicted_ratings_df.pkl')\n",
    "\n",
    "# def get_content_recommendations(movie_id, num_recommendations=10):\n",
    "#     movie_idx = data[data['id'] == movie_id].index[0]\n",
    "#     sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
    "#     sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "#     sim_scores = sim_scores[1:num_recommendations+1]\n",
    "#     movie_indices = [i[0] for i in sim_scores]\n",
    "#     return data['title'].iloc[movie_indices]\n",
    "\n",
    "# def get_popularity_recommendations(num_recommendations=10):\n",
    "#     popular_movies = data.sort_values('popularity', ascending=False)\n",
    "#     return popular_movies['title'].head(num_recommendations)\n",
    "\n",
    "# def hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=10):\n",
    "#     if user_id is None or user_id not in predicted_ratings_df.index:\n",
    "#         if movie_id is not None:\n",
    "#             return get_content_recommendations(movie_id, num_recommendations)\n",
    "#         else:\n",
    "#             return get_popularity_recommendations(num_recommendations)\n",
    "#     else:\n",
    "#         user_ratings = predicted_ratings_df.loc[user_id]\n",
    "#         cf_recommendations = user_ratings.sort_values(ascending=False).index[:num_recommendations]\n",
    "\n",
    "#         if movie_id is not None:\n",
    "#             content_recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "#             combined_recommendations = list(set(cf_recommendations).union(set(content_recommendations.index)))\n",
    "#             combined_scores = {}\n",
    "            \n",
    "#             movie_idx = data[data['id'] == movie_id].index[0]\n",
    "#             for idx in combined_recommendations:\n",
    "#                 cf_score = user_ratings.get(idx, 0)\n",
    "#                 content_score = cosine_sim[movie_idx][idx] if idx < len(cosine_sim) else 0\n",
    "#                 combined_scores[idx] = (cf_score + content_score) / 2\n",
    "            \n",
    "#             sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "#             return [data['title'].iloc[idx] for idx, score in sorted_recommendations]\n",
    "#         else:\n",
    "#             return data['title'].iloc[cf_recommendations]\n",
    "\n",
    "# # Example usage for a new user who picked a movie\n",
    "# new_user_movie_id = 299534  # Movie ID for \"Avengers: Endgame\"\n",
    "# recommendations = hybrid_recommendations(user_id=None, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "# print(f\"Recommendations for new user based on movie ID {new_user_movie_id}:\")\n",
    "# print(recommendations)\n",
    "\n",
    "# # Example usage for an existing user\n",
    "# existing_user_id = 10  # Assuming user ID 10 exists in predicted_ratings_df\n",
    "# recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "# print(f\"Recommendations for existing user with user ID {existing_user_id}:\")\n",
    "# print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cc3067-b28c-446f-94b2-24d3d08f4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Load the initial data\n",
    "# file_path = '/mnt/data/TMDB_Movies.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# # Preprocess the data\n",
    "# data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')\n",
    "# data.dropna(subset=['overview'], inplace=True)\n",
    "\n",
    "# # Load the scaler (if available)\n",
    "# try:\n",
    "#     with open('scaler.pkl', 'rb') as f:\n",
    "#         scaler = pickle.load(f)\n",
    "#     data[['popularity', 'vote_average']] = scaler.transform(data[['popularity', 'vote_average']])\n",
    "# except FileNotFoundError:\n",
    "#     scaler = StandardScaler()\n",
    "#     data[['popularity', 'vote_average']] = scaler.fit_transform(data[['popularity', 'vote_average']])\n",
    "#     # with open('scaler.pkl', 'wb') as f:\n",
    "#     #     pickle.dump(scaler, f)\n",
    "\n",
    "# Load existing components and models\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "with open('U_matrix.pkl', 'rb') as f:\n",
    "    U = pickle.load(f)\n",
    "with open('sigma_matrix.pkl', 'rb') as f:\n",
    "    sigma = pickle.load(f)\n",
    "with open('Vt_matrix.pkl', 'rb') as f:\n",
    "    Vt = pickle.load(f)\n",
    "\n",
    "cosine_sim = np.load('cosine_sim.npy')\n",
    "predicted_ratings_df = pd.read_pickle('predicted_ratings_df.pkl')\n",
    "\n",
    "\n",
    "def get_content_recommendations(movie_id, num_recommendations=10):\n",
    "    movie_idx = data[data['id'] == movie_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:num_recommendations+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return data['title'].iloc[movie_indices]\n",
    "    \n",
    "\n",
    "def get_popularity_recommendations(num_recommendations=10):\n",
    "    popular_movies = data.sort_values('popularity', ascending=False)\n",
    "    return popular_movies['title'].head(num_recommendations)\n",
    "\n",
    "def hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=10):\n",
    "    if user_id is None or user_id not in predicted_ratings_df.index:\n",
    "        if movie_id is not None:\n",
    "            return get_content_recommendations(movie_id, num_recommendations)\n",
    "        else:\n",
    "            return get_popularity_recommendations(num_recommendations)\n",
    "    else:\n",
    "        user_ratings = predicted_ratings_df.loc[user_id]\n",
    "        cf_recommendations = user_ratings.sort_values(ascending=False).index[:num_recommendations]\n",
    "\n",
    "        if movie_id is not None:\n",
    "            content_recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "            combined_recommendations = list(set(cf_recommendations).union(set(content_recommendations.index)))\n",
    "            combined_scores = {}\n",
    "            \n",
    "            movie_idx = data[data['id'] == movie_id].index[0]\n",
    "            for idx in combined_recommendations:\n",
    "                cf_score = user_ratings.get(idx, 0)\n",
    "                content_score = cosine_sim[movie_idx][idx] if idx < len(cosine_sim) else 0\n",
    "                combined_scores[idx] = (cf_score + content_score) / 2\n",
    "            \n",
    "            sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "            return [(int(data['id'].iloc[idx]),data['title'].iloc[idx]) for idx, score in sorted_recommendations]\n",
    "        else:\n",
    "            return data['title'].iloc[cf_recommendations]\n",
    "\n",
    "\n",
    "\n",
    "# # Example usage for a new user who picked a movie\n",
    "# new_user_movie_id = 299534  # Movie ID for \"Avengers: Endgame\"\n",
    "# recommendations = hybrid_recommendations(user_id=None, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "# print(f\"Recommendations for new user based on movie ID {new_user_movie_id}:\")\n",
    "# print(recommendations)\n",
    "\n",
    "# # Example usage for an existing user\n",
    "# existing_user_id = 10  # Assuming user ID 10 exists in predicted_ratings_df\n",
    "# recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "# print(f\"Recommendations for existing user with user ID {existing_user_id}:\")\n",
    "# print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c32ea7f-f85d-4085-ae82-b39370a1126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for new user based on movie ID 299534:\n",
      "[(299536, 'Avengers: Infinity War'), (271110, 'Captain America: Civil War'), (14613, 'Next Avengers: Heroes of Tomorrow'), (340382, 'Attack on Titan II: End of the World'), (299537, 'Captain Marvel')]\n",
      "Recommendations for existing user with user ID 10:\n",
      "[(214030, 'Fading Gigolo'), (760883, 'Blood Red Sky'), (49361, \"Don't Torture a Duckling\"), (51620, 'Death Race 2'), (43361, 'The White Sheik')]\n",
      "Recommendations for existing user with user ID 10 and movie ID 299534:\n",
      "[(760883, 'Blood Red Sky'), (214030, 'Fading Gigolo'), (49361, \"Don't Torture a Duckling\"), (51620, 'Death Race 2'), (43361, 'The White Sheik')]\n"
     ]
    }
   ],
   "source": [
    "new_user_movie_id = 299534  # Movie ID for \"Avengers: Endgame\"\n",
    "recommendations = hybrid_recommendations(user_id=None, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "print(f\"Recommendations for new user based on movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "\n",
    "existing_user_id = 10  # Assuming user ID 10 exists in predicted_ratings_df\n",
    "recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=None, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "\n",
    "existing_user_id = 10  # Assuming user ID 10 exists in predicted_ratings_df\n",
    "recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id} and movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a60c839-adf2-497d-a38f-5aa481602753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for existing user with user ID 10 and movie ID 299534:\n",
      "[(346698, 'Barbie'), (298618, 'The Flash'), (667538, 'Transformers: Rise of the Beasts'), (1040148, 'Ruby Gillman, Teenage Kraken'), (447365, 'Guardians of the Galaxy Vol. 3')]\n"
     ]
    }
   ],
   "source": [
    "existing_user_id = 10  # Assuming user ID 10 exists in predicted_ratings_df\n",
    "recommendations = hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id} and movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9af4ab-0ab4-4632-918e-847cbcd76c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for new user based on movie ID 299534:\n",
      "[(299536, 'Avengers: Infinity War'), (271110, 'Captain America: Civil War'), (14613, 'Next Avengers: Heroes of Tomorrow'), (340382, 'Attack on Titan II: End of the World'), (299537, 'Captain Marvel')]\n",
      "Recommendations for existing user with user ID 10:\n",
      "[(214030, 'Fading Gigolo'), (760883, 'Blood Red Sky'), (49361, \"Don't Torture a Duckling\"), (51620, 'Death Race 2'), (43361, 'The White Sheik')]\n",
      "Recommendations for existing user with user ID 10 and movie ID 299534:\n",
      "[(760883, 'Blood Red Sky'), (214030, 'Fading Gigolo'), (49361, \"Don't Torture a Duckling\"), (51620, 'Death Race 2'), (43361, 'The White Sheik')]\n",
      "Recommendations without user ID or movie ID:\n",
      "[(346698, 'Barbie'), (298618, 'The Flash'), (667538, 'Transformers: Rise of the Beasts'), (1040148, 'Ruby Gillman, Teenage Kraken'), (447365, 'Guardians of the Galaxy Vol. 3')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Load existing components and models\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "with open('U_matrix.pkl', 'rb') as f:\n",
    "    U = pickle.load(f)\n",
    "with open('sigma_matrix.pkl', 'rb') as f:\n",
    "    sigma = pickle.load(f)\n",
    "with open('Vt_matrix.pkl', 'rb') as f:\n",
    "    Vt = pickle.load(f)\n",
    "\n",
    "cosine_sim = np.load('cosine_sim.npy')\n",
    "predicted_ratings_df = pd.read_pickle('predicted_ratings_df.pkl')\n",
    "\n",
    "\n",
    "\n",
    "# Function to get content-based recommendations\n",
    "def get_content_recommendations(movie_id, num_recommendations=10):\n",
    "    movie_idx = data[data['id'] == movie_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:num_recommendations+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in movie_indices]\n",
    "\n",
    "# Function to get popularity-based recommendations\n",
    "def get_popularity_recommendations(num_recommendations=10):\n",
    "    popular_movies = data.sort_values('popularity', ascending=False)\n",
    "    movie_indices = popular_movies.index[:num_recommendations]\n",
    "    return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in movie_indices]\n",
    "\n",
    "# Function to get hybrid recommendations\n",
    "def hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=10):\n",
    "    if user_id is None or user_id not in predicted_ratings_df.index:\n",
    "        if movie_id is not None:\n",
    "            return get_content_recommendations(movie_id, num_recommendations)\n",
    "        else:\n",
    "            return get_popularity_recommendations(num_recommendations)\n",
    "    else:\n",
    "        user_ratings = predicted_ratings_df.loc[user_id]\n",
    "        cf_recommendations = user_ratings.sort_values(ascending=False).index[:num_recommendations]\n",
    "\n",
    "        if movie_id is not None:\n",
    "            content_recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "            combined_recommendations = list(set(cf_recommendations).union(set([idx for idx, title in content_recommendations])))\n",
    "            combined_scores = {}\n",
    "\n",
    "            movie_idx = data[data['id'] == movie_id].index[0]\n",
    "            for idx in combined_recommendations:\n",
    "                cf_score = user_ratings.get(idx, 0)\n",
    "                content_score = cosine_sim[movie_idx][idx] if idx < len(cosine_sim) else 0\n",
    "                combined_scores[idx] = (cf_score + content_score) / 2\n",
    "\n",
    "            sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "            return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx, score in sorted_recommendations]\n",
    "        else:\n",
    "            return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in cf_recommendations]\n",
    "\n",
    "# Example usage for different scenarios\n",
    "new_user_movie_id = 299534  # Movie ID for \"Avengers: Endgame\"\n",
    "recommendations = hybrid_recommendations(user_id=None, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "print(f\"Recommendations for new user based on movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "existing_user_id = 10  # Assuming user ID 10 exists in predicted_ratings_df\n",
    "recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=None, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id} and movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "recommendations = hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=5)\n",
    "print(f\"Recommendations without user ID or movie ID:\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40f8012-1bd0-436c-b62d-b561374fd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Load existing components and models\n",
    "\n",
    "data = pd.read_csv('preprocessed_data.csv')\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "with open('U_matrix.pkl', 'rb') as f:\n",
    "    U = pickle.load(f)\n",
    "with open('sigma_matrix.pkl', 'rb') as f:\n",
    "    sigma = pickle.load(f)\n",
    "with open('Vt_matrix.pkl', 'rb') as f:\n",
    "    Vt = pickle.load(f)\n",
    "\n",
    "cosine_sim = np.load('cosine_sim.npy')\n",
    "predicted_ratings_df = pd.read_pickle('predicted_ratings_df.pkl')\n",
    "\n",
    "def get_content_recommendations(movie_id, num_recommendations=10):\n",
    "    movie_idx = data[data['id'] == movie_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:num_recommendations+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in movie_indices]\n",
    "\n",
    "def get_popularity_recommendations(num_recommendations=10):\n",
    "    popular_movies = data.sort_values('popularity', ascending=False)\n",
    "    movie_indices = popular_movies.index[:num_recommendations]\n",
    "    return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in movie_indices]\n",
    "\n",
    "def hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=10):\n",
    "    if user_id is None or user_id not in predicted_ratings_df.index:\n",
    "        if movie_id is not None:\n",
    "            return get_content_recommendations(movie_id, num_recommendations)\n",
    "        else:\n",
    "            return get_popularity_recommendations(num_recommendations)\n",
    "    else:\n",
    "        user_ratings = predicted_ratings_df.loc[user_id]\n",
    "        cf_recommendations = user_ratings.sort_values(ascending=False).index[:num_recommendations]\n",
    "\n",
    "        if movie_id is not None:\n",
    "            content_recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "            combined_recommendations = list(set(cf_recommendations).union(set([idx for idx, title in content_recommendations])))\n",
    "            combined_scores = {}\n",
    "\n",
    "            movie_idx = data[data['id'] == movie_id].index[0]\n",
    "            for idx in combined_recommendations:\n",
    "                cf_score = user_ratings.get(idx, 0)\n",
    "                content_score = cosine_sim[movie_idx][idx] if idx < len(cosine_sim) else 0\n",
    "                combined_scores[idx] = (cf_score + content_score) / 2\n",
    "\n",
    "            sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "            return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx, score in sorted_recommendations]\n",
    "        else:\n",
    "            return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in cf_recommendations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e8a0e2-d766-4b6d-bebd-f4be95b6ca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for new user based on movie ID 299534:\n",
      "[(299536, 'Avengers: Infinity War'), (271110, 'Captain America: Civil War'), (14613, 'Next Avengers: Heroes of Tomorrow'), (340382, 'Attack on Titan II: End of the World'), (299537, 'Captain Marvel')]\n",
      "Recommendations for existing user with user ID 10:\n",
      "[(214030, 'Fading Gigolo'), (760883, 'Blood Red Sky'), (49361, \"Don't Torture a Duckling\"), (51620, 'Death Race 2'), (43361, 'The White Sheik')]\n",
      "Recommendations for existing user with user ID 10 and movie ID 299534:\n",
      "[(760883, 'Blood Red Sky'), (214030, 'Fading Gigolo'), (49361, \"Don't Torture a Duckling\"), (51620, 'Death Race 2'), (43361, 'The White Sheik')]\n",
      "Recommendations without user ID or movie ID:\n",
      "[(346698, 'Barbie'), (298618, 'The Flash'), (667538, 'Transformers: Rise of the Beasts'), (1040148, 'Ruby Gillman, Teenage Kraken'), (447365, 'Guardians of the Galaxy Vol. 3')]\n"
     ]
    }
   ],
   "source": [
    "# Example usage for different scenarios\n",
    "new_user_movie_id = 299534  # Movie ID for \"Avengers: Endgame\"\n",
    "recommendations = hybrid_recommendations(user_id=None, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "print(f\"Recommendations for new user based on movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "existing_user_id = 10  # Assuming user ID 10 exists in predicted_ratings_df\n",
    "recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=None, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "recommendations = hybrid_recommendations(user_id=existing_user_id, movie_id=new_user_movie_id, num_recommendations=5)\n",
    "print(f\"Recommendations for existing user with user ID {existing_user_id} and movie ID {new_user_movie_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "recommendations = hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=5)\n",
    "print(f\"Recommendations without user ID or movie ID:\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911fd6b1-6084-4b58-a73d-c5d7c18cae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Load existing components and models\n",
    "\n",
    "data = pd.read_csv('preprocessed_data.csv')\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "with open('U_matrix.pkl', 'rb') as f:\n",
    "    U = pickle.load(f)\n",
    "with open('sigma_matrix.pkl', 'rb') as f:\n",
    "    sigma = pickle.load(f)\n",
    "with open('Vt_matrix.pkl', 'rb') as f:\n",
    "    Vt = pickle.load(f)\n",
    "\n",
    "cosine_sim = np.load('cosine_sim.npy')\n",
    "predicted_ratings_df = pd.read_pickle('predicted_ratings_df.pkl')\n",
    "def get_content_recommendations(movie_id, num_recommendations=10):\n",
    "    movie_idx = data[data['id'] == movie_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:num_recommendations+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in movie_indices]\n",
    "\n",
    "def get_popularity_recommendations(num_recommendations=10):\n",
    "    popular_movies = data.sort_values('popularity', ascending=False)\n",
    "    movie_indices = popular_movies.index[:num_recommendations]\n",
    "    return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in movie_indices]\n",
    "\n",
    "def hybrid_recommendations(user_id=None, movie_id=None, num_recommendations=10):\n",
    "    if user_id is None or user_id not in predicted_ratings_df.index:\n",
    "        if movie_id is not None:\n",
    "            return get_content_recommendations(movie_id, num_recommendations)\n",
    "        else:\n",
    "            return get_popularity_recommendations(num_recommendations)\n",
    "    else:\n",
    "        user_ratings = predicted_ratings_df.loc[user_id]\n",
    "        cf_recommendations = user_ratings.sort_values(ascending=False).index[:num_recommendations]\n",
    "\n",
    "        if movie_id is not None:\n",
    "            content_recommendations = get_content_recommendations(movie_id, num_recommendations)\n",
    "            combined_recommendations = list(set(cf_recommendations).union(set([idx for idx, title in content_recommendations])))\n",
    "            combined_scores = {}\n",
    "\n",
    "            movie_idx = data[data['id'] == movie_id].index[0]\n",
    "            for idx in combined_recommendations:\n",
    "                cf_score = user_ratings.get(idx, 0)\n",
    "                content_score = cosine_sim[movie_idx][idx] if idx < len(cosine_sim) else 0\n",
    "                combined_scores[idx] = (cf_score + content_score) / 2\n",
    "\n",
    "            sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "            return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx, score in sorted_recommendations]\n",
    "        else:\n",
    "            return [(int(data['id'].iloc[idx]), data['title'].iloc[idx]) for idx in cf_recommendations]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ffd95a-3664-4822-a77f-c0d61322d38c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mhybrid_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_recommendations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommendations without user ID or movie ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(recommendations)\n",
      "Cell \u001b[0;32mIn[1], line 47\u001b[0m, in \u001b[0;36mhybrid_recommendations\u001b[0;34m(user_id, movie_id, num_recommendations)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     user_ratings \u001b[38;5;241m=\u001b[39m predicted_ratings_df\u001b[38;5;241m.\u001b[39mloc[user_id]\n\u001b[0;32m---> 47\u001b[0m     cf_recommendations \u001b[38;5;241m=\u001b[39m \u001b[43muser_ratings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_recommendations\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m movie_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m         content_recommendations \u001b[38;5;241m=\u001b[39m get_content_recommendations(movie_id, num_recommendations)\n",
      "File \u001b[0;32m~/Documents/FilmFusion/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:5394\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m getitem(key)\n\u001b[1;32m   5391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   5392\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5393\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m-> 5394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   5397\u001b[0m     \u001b[38;5;66;03m# if we have list[bools, length=1e5] then doing this check+convert\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m     \u001b[38;5;66;03m#  takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__\u001b[39;00m\n\u001b[1;32m   5399\u001b[0m     \u001b[38;5;66;03m#  time below from 3.8 ms to 496 µs\u001b[39;00m\n\u001b[1;32m   5400\u001b[0m     \u001b[38;5;66;03m# if we already have ndarray[bool], the overhead is 1.4 µs or .25%\u001b[39;00m\n\u001b[1;32m   5401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), ExtensionDtype):\n",
      "File \u001b[0;32m~/Documents/FilmFusion/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:5429\u001b[0m, in \u001b[0;36mIndex._getitem_slice\u001b[0;34m(self, slobj)\u001b[0m\n\u001b[1;32m   5425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_slice\u001b[39m(\u001b[38;5;28mself\u001b[39m, slobj: \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   5426\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5427\u001b[0m \u001b[38;5;124;03m    Fastpath for __getitem__ when we know we have a slice.\u001b[39;00m\n\u001b[1;32m   5428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5429\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslobj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   5430\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(res, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, refs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_references)\n\u001b[1;32m   5431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_engine\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache:\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "recommendations = hybrid_recommendations(user_id=10, movie_id=None, num_recommendations=\"5\")\n",
    "print(f\"Recommendations without user ID or movie ID:\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513ef9c-f4ac-4be1-9fe6-1b4de74f3f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
